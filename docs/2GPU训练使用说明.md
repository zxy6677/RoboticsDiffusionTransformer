# 2-GPUè®­ç»ƒä½¿ç”¨è¯´æ˜

## ğŸ¯ æ–¹æ¡ˆï¼šAccelerateå¤šGPUï¼ˆå·²é€‰æ‹©ï¼‰

ä½¿ç”¨Accelerateçš„åŸç”Ÿå¤šGPUæ”¯æŒï¼Œç®€å•é«˜æ•ˆã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
```bash
chmod +x train_single_task_2gpu.sh
```

### 2. å¯åŠ¨è®­ç»ƒ
```bash
bash train_single_task_2gpu.sh
```

æˆ–è€…ç›´æ¥è¿è¡Œï¼š
```bash
./train_single_task_2gpu.sh
```

---

## ğŸ“Š å…³é”®é…ç½®å˜åŒ–

### ä¸å•GPUè®­ç»ƒçš„å¯¹æ¯”

| é…ç½®é¡¹ | å•GPU | 2-GPU | è¯´æ˜ |
|--------|-------|-------|------|
| **GPUè®¾å¤‡** | `CUDA_VISIBLE_DEVICES=1` | `CUDA_VISIBLE_DEVICES=0,1` | ä½¿ç”¨GPU 0å’Œ1 |
| **å¯åŠ¨æ–¹å¼** | `python main.py` | `accelerate launch --num_processes 2 --multi_gpu` | å¤šè¿›ç¨‹å¯åŠ¨ |
| **Batch Size** | 8 | 16 | 2å€ï¼ˆæ¯å¡8ï¼‰ |
| **Dataloader Workers** | 4 | 8 | 2å€åŠ é€Ÿæ•°æ®åŠ è½½ |
| **è®­ç»ƒé€Ÿåº¦** | 1.0x | ~1.8-1.9x | å®é™…åŠ é€Ÿæ¯” |

### ä¸ºä»€ä¹ˆä¸æ˜¯2.0xåŠ é€Ÿï¼Ÿ

- GPUé—´é€šä¿¡å¼€é”€ï¼š~5-10%
- æ¢¯åº¦åŒæ­¥æ—¶é—´ï¼š~5%
- å®é™…åŠ é€Ÿæ¯”ï¼š1.8-1.9xï¼ˆéå¸¸å¥½çš„ç»“æœï¼ï¼‰

---

## âš™ï¸ å‚æ•°è¯´æ˜

### Accelerateå‚æ•°

```bash
accelerate launch \
    --num_processes 2 \        # ä½¿ç”¨2ä¸ªè¿›ç¨‹ï¼ˆå¯¹åº”2å¼ GPUï¼‰
    --multi_gpu \               # å¯ç”¨å¤šGPUæ¨¡å¼
    --mixed_precision bf16 \    # bfloat16æ··åˆç²¾åº¦
    main.py \
    ...
```

### è®­ç»ƒå‚æ•°ä¼˜åŒ–

```bash
--train_batch_size=16          # æ€»batch size (æ¯GPU=8)
--sample_batch_size=16         # é‡‡æ ·batch size
--dataloader_num_workers=8     # æ•°æ®åŠ è½½workeræ•°
```

---

## ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. Batch Sizeè°ƒä¼˜

æ ¹æ®æ˜¾å­˜ä½¿ç”¨æƒ…å†µè°ƒæ•´ï¼š

```bash
# ä¿å®ˆï¼ˆå®‰å…¨ï¼‰
--train_batch_size=16    # æ¯GPU: 8

# ä¸­ç­‰ï¼ˆæ¨èï¼‰
--train_batch_size=20    # æ¯GPU: 10

# æ¿€è¿›ï¼ˆå¦‚æœæ˜¾å­˜å¤Ÿï¼‰
--train_batch_size=24    # æ¯GPU: 12
```

**ç›‘æ§å‘½ä»¤**ï¼š
```bash
# å¦å¼€ä¸€ä¸ªç»ˆç«¯ï¼Œç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi
```

### 2. Dataloader Workersè°ƒä¼˜

```bash
# CPUæ ¸å¿ƒè¾ƒå°‘
--dataloader_num_workers=4

# CPUæ ¸å¿ƒå……è¶³ï¼ˆæ¨èï¼‰
--dataloader_num_workers=8

# CPUæ ¸å¿ƒå¾ˆå¤š
--dataloader_num_workers=12
```

### 3. Gradient Accumulation

å¦‚æœæƒ³ç”¨æ›´å¤§çš„æœ‰æ•ˆbatch sizeä½†æ˜¾å­˜ä¸å¤Ÿï¼š

```bash
--train_batch_size=16
--gradient_accumulation_steps=2
# æœ‰æ•ˆbatch size = 16 * 2 = 32
```

---

## ğŸ” è®­ç»ƒç›‘æ§

### 1. æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ

```bash
# å®æ—¶ç›‘æ§
watch -n 1 nvidia-smi

# æŸ¥çœ‹ä¸€æ¬¡
nvidia-smi
```

**æœŸæœ›çœ‹åˆ°**ï¼š
- ä¸¤å¼ GPUçš„Utilizationéƒ½åœ¨80-100%
- Memoryä½¿ç”¨ç›¸è¿‘
- Powerä½¿ç”¨éƒ½åœ¨300W+ï¼ˆ4090æ»¡è½½ï¼‰

### 2. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒè¾“å‡º
tail -f checkpoints/single_task_scene10_2gpu/training.log

# æˆ–è€…ç›´æ¥åœ¨è¿è¡Œç»ˆç«¯è§‚å¯Ÿ
```

### 3. è®­ç»ƒé€Ÿåº¦ä¼°ç®—

```python
# å‡è®¾å•GPUè®­ç»ƒé€Ÿåº¦ï¼š5ç§’/step
# 2-GPUé¢„æœŸé€Ÿåº¦ï¼š2.7ç§’/step (1.8xåŠ é€Ÿ)
# 20000æ­¥æ€»æ—¶é—´ï¼š
#   å•GPU: 20000 * 5 / 3600 = 27.8å°æ—¶
#   2-GPU: 20000 * 2.7 / 3600 = 15å°æ—¶ âœ…
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ä¸¤å¼ GPUåˆ©ç”¨ç‡ä¸å‡è¡¡ï¼Ÿ

**åŸå› **ï¼šæ•°æ®ä¸å‡åŒ€æˆ–batch sizeå¤ªå°

**è§£å†³**ï¼š
```bash
# å¢åŠ batch size
--train_batch_size=20  # æˆ–æ›´å¤§
```

### Q2: è®­ç»ƒé€Ÿåº¦æ²¡æœ‰æå‡ï¼Ÿ

**æ£€æŸ¥æ¸…å•**ï¼š
1. ç¡®è®¤ä¸¤å¼ GPUéƒ½åœ¨å·¥ä½œï¼š`nvidia-smi`
2. æ•°æ®åŠ è½½æ˜¯å¦æ˜¯ç“¶é¢ˆï¼šå¢åŠ `--dataloader_num_workers`
3. Batch sizeæ˜¯å¦è¶³å¤Ÿï¼šè‡³å°‘16ï¼ˆæ¯GPU 8ï¼‰

### Q3: æ˜¾å­˜ä¸è¶³OOMï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ–¹æ¡ˆ1ï¼šå‡å°batch size
--train_batch_size=12  # æ¯GPU: 6

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨gradient accumulation
--train_batch_size=12
--gradient_accumulation_steps=2
```

### Q4: å¦‚ä½•åªç”¨å•å¼ GPUè®­ç»ƒï¼Ÿ

ä½¿ç”¨åŸæ¥çš„è„šæœ¬ï¼š
```bash
bash train_single_task.sh
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”é¢„æœŸ

| æŒ‡æ ‡ | å•GPU (4090) | 2-GPU (4090x2) |
|------|--------------|----------------|
| **Batch Size** | 8 | 16 |
| **æ­¥éª¤æ—¶é—´** | ~5ç§’/step | ~2.7ç§’/step |
| **20Kæ­¥æ€»æ—¶é—´** | ~28å°æ—¶ | ~15å°æ—¶ âœ… |
| **GPUåˆ©ç”¨ç‡** | 90-100% | 85-95% (each) |
| **æ˜¾å­˜ä½¿ç”¨** | ~35GB | ~35GB (each) |

---

## âœ… éªŒè¯è®­ç»ƒæ­£å¸¸è¿è¡Œ

### å¯åŠ¨ååº”è¯¥çœ‹åˆ°ï¼š

```
============================================
ä½¿ç”¨2å¼ GPUè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
GPUè®¾å¤‡: 0,1
é¢„æœŸåŠ é€Ÿ: çº¦1.8-1.9x (2å¼ GPU, è€ƒè™‘é€šä¿¡å¼€é”€)
============================================

ğŸ” æ£€æµ‹åˆ°å•ä»»åŠ¡è®­ç»ƒï¼Œä½¿ç”¨ libero_single_task ç»Ÿè®¡ä¿¡æ¯
âœ… ä½¿ç”¨æ­£ç¡®çš„å•ä»»åŠ¡ç»Ÿè®¡ï¼ˆPosition stdä¿®å¤ï¼‰

Distributed training: world_size=2, rank=0
Distributed training: world_size=2, rank=1

Steps:   0%|          | 0/20000 [00:00<?, ?it/s]
...
```

### å…³é”®ä¿¡æ¯ç¡®è®¤ï¼š

- âœ… `world_size=2`ï¼šç¡®è®¤2ä¸ªè¿›ç¨‹
- âœ… `rank=0`, `rank=1`ï¼šä¸¤ä¸ªGPUéƒ½åœ¨å·¥ä½œ
- âœ… `æ£€æµ‹åˆ°å•ä»»åŠ¡è®­ç»ƒ`ï¼šä½¿ç”¨æ­£ç¡®ç»Ÿè®¡
- âœ… GPUåˆ©ç”¨ç‡ï¼šä¸¤å¼ éƒ½åœ¨80%+

---

## ğŸ¯ è®­ç»ƒå®Œæˆå

### 1. æ£€æŸ¥checkpoint
```bash
ls -lh checkpoints/single_task_scene10_2gpu/checkpoint-*/
```

### 2. è¯„ä¼°æ¨¡å‹
```bash
export CUDA_VISIBLE_DEVICES=0  # è¯„ä¼°åªéœ€1å¼ GPU

python eval_sim/eval_rdt_libero.py \
    --config configs/base.yaml \
    --pretrained checkpoints/single_task_scene10_2gpu/checkpoint-19000/ema/model.safetensors \
    --text_encoder google/t5-v1_1-xxl \
    --vision_encoder google/siglip-so400m-patch14-384 \
    --benchmark libero_90 \
    --num_tasks 2 \
    --max_steps 200 \
    --exec_horizon 16 \
    --record_video \
    --video_output_dir videos/single_task_2gpu_eval
```

---

## ğŸ’¾ èŠ‚çœæ—¶é—´ä¼°ç®—

| è®­ç»ƒæ­¥æ•° | å•GPUæ—¶é—´ | 2-GPUæ—¶é—´ | èŠ‚çœæ—¶é—´ |
|---------|-----------|-----------|----------|
| 5,000æ­¥ | ~7å°æ—¶ | ~4å°æ—¶ | **3å°æ—¶** |
| 10,000æ­¥ | ~14å°æ—¶ | ~7.5å°æ—¶ | **6.5å°æ—¶** |
| 20,000æ­¥ | ~28å°æ—¶ | ~15å°æ—¶ | **13å°æ—¶** âœ… |

**ç»“è®ºï¼š20Kæ­¥è®­ç»ƒå¯ä»¥èŠ‚çœåŠå¤©æ—¶é—´ï¼**

---

## ğŸ”§ é«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰

### 1. è‡ªå®šä¹‰GPUé€‰æ‹©

```bash
# ä½¿ç”¨GPU 1å’Œ2ï¼ˆè€Œä¸æ˜¯0å’Œ1ï¼‰
export CUDA_VISIBLE_DEVICES=1,2
bash train_single_task_2gpu.sh
```

### 2. è°ƒæ•´æ··åˆç²¾åº¦

```bash
# å¦‚æœé‡åˆ°æ•°å€¼ç¨³å®šæ€§é—®é¢˜ï¼Œå¯ä»¥æ”¹ç”¨fp16
accelerate launch \
    --mixed_precision fp16 \  # æ”¹ä¸ºfp16
    ...
```

### 3. è°ƒæ•´é€šä¿¡åç«¯

```bash
# å¦‚æœé‡åˆ°é€šä¿¡é—®é¢˜ï¼Œå¯ä»¥å°è¯•
export NCCL_DEBUG=INFO
export NCCL_P2P_DISABLE=1  # ç¦ç”¨P2Pï¼ˆå¦‚æœæœ‰é—®é¢˜ï¼‰
```

---

## ğŸ“ æ€»ç»“

### æ¨èé…ç½®ï¼ˆ2x 4090ï¼‰

```bash
âœ… GPUè®¾å¤‡: 0,1
âœ… Batch Size: 16-20
âœ… Workers: 8
âœ… æ··åˆç²¾åº¦: bf16
âœ… é¢„æœŸåŠ é€Ÿ: 1.8-1.9x
âœ… è®­ç»ƒæ—¶é—´: 15å°æ—¶ï¼ˆ20Kæ­¥ï¼‰
```

### ç«‹å³å¼€å§‹è®­ç»ƒ

```bash
bash train_single_task_2gpu.sh
```

**ä½¿ç”¨ä¿®å¤åçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œé¢„æœŸä»»åŠ¡2çš„æˆåŠŸç‡ä¼šæ˜¾è‘—æå‡ï¼** ğŸš€

