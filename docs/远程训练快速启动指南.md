# 远程训练快速启动指南 🚀

## 核心问题解答 ❓

### Q: 是否需要重新计算统计信息？

**答：不需要！** ✅

验证结果：
```bash
# 本地数据集校验和
1a602b00ddcd0a7d0edfad722e1c9f0d  datasets/libero_single_task/KITCHEN_SCENE10...hdf5

# 远程数据集校验和  
1a602b00ddcd0a7d0edfad722e1c9f0d  data/datasets/libero_single_task/KITCHEN_SCENE10...hdf5
```

**MD5完全一致** → 数据集相同 → **无需重新计算统计信息**

---

### Q: 缺少 `model.safetensors` 怎么办？

**答：这不是问题！** ✅

**训练代码自动支持两种格式：**

1. **优先加载**: `model.safetensors` (SafeTensors格式)
2. **备用加载**: `pytorch_model.bin` (PyTorch原生格式)

代码逻辑 (`models/hub_mixin.py:42-49`):
```python
if os.path.isdir(model_id):
    try:
        # 先尝试加载 SafeTensors
        model_file = os.path.join(model_id, "model.safetensors")
        return cls._load_as_safetensor(model, model_file, ...)
    except FileNotFoundError:
        # 如果不存在，加载 PyTorch格式
        model_file = os.path.join(model_id, "pytorch_model.bin")
        return cls._load_as_pickle(model, model_file, ...)
```

**您的 rdt-1b 使用 `pytorch_model.bin` 是完全正常的！**

---

## 远程服务器当前状态 📊

### ✅ 已就绪项

| 项目 | 状态 | 说明 |
|------|------|------|
| 代码更新 | ✅ | 已pull到最新版本 (922adfe) |
| 数据集 | ✅ | 1.0GB, MD5与本地一致 |
| 统计信息 | ✅ | libero_single_task已存在，数值正常 |
| GPU | ✅ | 8张 A800-80GB 全部可用 |
| 配置文件 | ✅ | 所有配置文件完整 |
| 训练脚本 | ✅ | train_single_task_2gpu.sh 已配置8-GPU |
| 磁盘空间 | ✅ | 45GB可用 |
| 文本编码器 | ✅ | google/t5-v1_1-xxl |
| 视觉编码器 | ✅ | google/siglip-so400m-patch14-384 |

### ⚠️ 需要处理项

| 项目 | 状态 | 解决方案 |
|------|------|----------|
| Conda环境 | ⚠️ | `conda activate rdt` |
| Python依赖 | ⚠️ | 激活rdt环境后自动可用 |
| 预训练模型 | ⚠️ | 需要上传 `checkpoints/rdt-1b/` |

---

## 立即开始训练的步骤 🎯

### 方案1: 上传预训练模型后训练（推荐）

```bash
# === 在本地 ===
cd /home/ubuntu/RoboticsDiffusionTransformer

# 1. 打包预训练模型
tar -czf rdt-1b.tar.gz checkpoints/rdt-1b/

# 2. 上传到远程服务器
scp -o "ProxyJump zhukefei@134.175.121.223" \
    rdt-1b.tar.gz \
    zhukefei@172.16.0.27:~/RoboticsDiffusionTransformer/

# === 在远程服务器 ===
ssh -J zhukefei@134.175.121.223 zhukefei@172.16.0.27

cd ~/RoboticsDiffusionTransformer

# 3. 解压
tar -xzf rdt-1b.tar.gz
rm rdt-1b.tar.gz

# 4. 验证
ls -lh checkpoints/rdt-1b/pytorch_model.bin
# 应该显示 2.3G

# 5. 激活环境
conda activate rdt

# 6. 再次运行检查（可选）
bash remote_training_check.sh

# 7. 开始训练
tmux new -s training
bash train_single_task_2gpu.sh
```

### 方案2: 从头训练（不推荐，需要很长时间）

如果不上传预训练模型，训练脚本会从随机初始化开始训练，需要更多时间收敛。

---

## 预训练模型文件结构 📁

正确的 `checkpoints/rdt-1b/` 结构：

```
checkpoints/rdt-1b/
├── config.json              ← 模型配置 (必需)
├── pytorch_model.bin        ← 模型权重 (必需，2.3GB)
└── README.md                ← 说明文档 (可选)
```

**注意**：
- `pytorch_model.bin` 和 `model.safetensors` 是两种不同格式，只需要其中一种
- rdt-1b 官方使用的是 `pytorch_model.bin`
- 训练代码会自动选择可用的格式

---

## 完整检查命令 🔍

在远程服务器上运行：

```bash
cd ~/RoboticsDiffusionTransformer
conda activate rdt
bash remote_training_check.sh
```

检查脚本会验证：
- ✓ Python环境和依赖
- ✓ 8张GPU状态
- ✓ 数据集文件 (验证MD5)
- ✓ 统计信息 (libero_single_task)
- ✓ 配置文件完整性
- ✓ 预训练模型 (两种格式)
- ✓ 磁盘空间

---

## 预期训练配置 ⚙️

```bash
# 硬件配置
GPU: 8张 A800-80GB (80GB显存/GPU)
总显存: 640GB

# 训练参数
num_processes: 8
train_batch_size: 4 (每GPU)
总batch size: 32
gradient_accumulation: 1
有效batch size: 32

learning_rate: 1e-4
max_train_steps: 30000
checkpointing_period: 2000

# 预计时间
总训练时间: ~3-4小时 (8-GPU)
Checkpoint保存: 每2000步
预计Checkpoint数量: 15个
```

---

## 训练监控 📈

### 使用tmux（推荐）

```bash
# 创建会话
tmux new -s training

# 运行训练
bash train_single_task_2gpu.sh

# 分离会话: Ctrl+B, 然后按 D
# 重新连接: tmux attach -t training

# 查看所有会话
tmux ls

# 结束会话
tmux kill-session -t training
```

### GPU监控

```bash
# 实时监控GPU
watch -n 1 nvidia-smi

# 或使用gpustat（如果安装）
watch -n 1 gpustat
```

### 日志监控

```bash
# 如果使用nohup
tail -f train.log

# 查看训练步数
grep "step" train.log | tail -20
```

### Checkpoint检查

```bash
# 查看已保存的checkpoint
ls -lht checkpoints/single_task_scene10_2gpu/ | head

# 查看最新checkpoint
ls -lhtr checkpoints/single_task_scene10_2gpu/checkpoint-*/
```

---

## 故障排查 🔧

### 问题1: CUDA Out of Memory

```bash
# 解决方案1: 减少batch size
# 修改 train_single_task_2gpu.sh
--train_batch_size=2  # 从4改为2

# 解决方案2: 启用gradient checkpointing
--gradient_checkpointing
```

### 问题2: 数据加载慢

```bash
# 检查dataloader workers
--dataloader_num_workers=8  # 当前设置

# 如果CPU不足，可以减少
--dataloader_num_workers=4
```

### 问题3: 找不到模块

```bash
# 确保在项目根目录
pwd  # 应该是 /home/zhukefei/RoboticsDiffusionTransformer

# 确保conda环境激活
conda activate rdt

# 检查Python路径
python -c "import sys; print(sys.path)"
```

### 问题4: 编码器下载慢

```bash
# 使用HuggingFace镜像
export HF_ENDPOINT=https://hf-mirror.com

# 或者从本地上传编码器
# 本地打包
tar -czf encoders.tar.gz google/

# 上传并解压
scp -o "ProxyJump ..." encoders.tar.gz ...
tar -xzf encoders.tar.gz
```

---

## 关键环境变量 🔑

```bash
# 数据集路径（自动检测，无需手动设置）
export LIBERO_DATASET_DIR="./data/datasets/libero_single_task"

# GPU选择
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# HuggingFace（可选）
export HF_ENDPOINT=https://hf-mirror.com  # 使用镜像
export HF_HOME=/path/to/cache             # 缓存目录

# Weights & Biases（可选）
export WANDB_MODE=offline                 # 离线模式
export WANDB_DISABLED=true                # 禁用W&B
```

---

## 训练完成后 🎉

### 1. 查看checkpoint

```bash
ls -lh checkpoints/single_task_scene10_2gpu/checkpoint-*/
```

### 2. 选择最佳checkpoint

通常最后一个checkpoint (step 30000) 效果最好，但也可以根据验证loss选择。

### 3. 运行评估

```bash
export CUDA_VISIBLE_DEVICES=0

python eval_sim/eval_rdt_libero.py \
    --config configs/base.yaml \
    --pretrained checkpoints/single_task_scene10_2gpu/checkpoint-30000/ema/model.safetensors \
    --text_encoder google/t5-v1_1-xxl \
    --vision_encoder google/siglip-so400m-patch14-384 \
    --benchmark libero_90 \
    --num_tasks 2 \
    --max_steps 200 \
    --exec_horizon 16 \
    --record_video \
    --video_output_dir videos/remote_8gpu_eval
```

### 4. 下载结果

```bash
# 在本地运行
scp -o "ProxyJump zhukefei@134.175.121.223" \
    -r zhukefei@172.16.0.27:~/RoboticsDiffusionTransformer/videos/remote_8gpu_eval \
    ./videos/

scp -o "ProxyJump zhukefei@134.175.121.223" \
    -r zhukefei@172.16.0.27:~/RoboticsDiffusionTransformer/checkpoints/single_task_scene10_2gpu/checkpoint-30000 \
    ./checkpoints/remote_8gpu_checkpoint/
```

---

## 总结 📝

### 立即可以开始训练！

**前提条件**：
1. ✅ 数据集已就绪（MD5验证通过）
2. ✅ 统计信息正确（无需重新计算）
3. ⚠️ 需要上传预训练模型 `checkpoints/rdt-1b/pytorch_model.bin`

**最快启动路径**：
```bash
# 1. 上传预训练模型（本地→远程）
scp -o "ProxyJump ..." rdt-1b.tar.gz ...

# 2. 远程解压
tar -xzf rdt-1b.tar.gz

# 3. 激活环境并训练
conda activate rdt
tmux new -s training
bash train_single_task_2gpu.sh
```

**预计时间**：
- 上传模型：~5-10分钟（2.3GB）
- 训练时间：~3-4小时（8-GPU, 30000步）
- 总计：~4小时

---

**状态**：✅ 所有准备工作完成，只需上传预训练模型即可开始！

**最后更新**：2024-10-19

