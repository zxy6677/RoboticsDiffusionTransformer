# è¿œç¨‹è®­ç»ƒæ³¨æ„äº‹é¡¹ âš ï¸

## æ ¸å¿ƒé—®é¢˜ï¼šæ˜¯å¦éœ€è¦é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼Ÿ

### ç­”æ¡ˆï¼š**è§†æƒ…å†µè€Œå®š** ğŸ¯

ç»Ÿè®¡ä¿¡æ¯å­˜å‚¨åœ¨ `configs/dataset_stat.json` ä¸­ï¼Œç”¨äºï¼š
1. **Lossæƒé‡è®¡ç®—** - ä¸åŒç»´åº¦çš„æŸå¤±åŠ æƒ
2. **æ•°æ®å½’ä¸€åŒ–** - è®­ç»ƒæ—¶çš„è¾“å…¥/è¾“å‡ºå½’ä¸€åŒ–

### ä½•æ—¶éœ€è¦é‡æ–°è®¡ç®—ï¼Ÿ

#### âœ… **éœ€è¦é‡æ–°è®¡ç®—çš„æƒ…å†µ**

1. **è¿œç¨‹æ•°æ®é›†ä¸æœ¬åœ°ä¸åŒ**
   ```bash
   # è¿œç¨‹: /home/zhukefei/RoboticsDiffusionTransformer/data/datasets/libero_single_task/
   # æœ¬åœ°: /home/ubuntu/RoboticsDiffusionTransformer/datasets/libero_single_task/
   
   # å¦‚æœæ–‡ä»¶æ•°é‡ã€å†…å®¹ã€demoæ•°é‡ä¸åŒï¼Œå¿…é¡»é‡æ–°è®¡ç®—
   ```

2. **configs/dataset_stat.json ç¼ºå°‘ libero_single_task**
   ```bash
   # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
   grep "libero_single_task" configs/dataset_stat.json
   
   # å¦‚æœæ²¡æœ‰è¾“å‡ºï¼Œéœ€è¦é‡æ–°è®¡ç®—
   ```

3. **ç»Ÿè®¡å€¼å¼‚å¸¸**
   - æ ‡å‡†å·® > 100ï¼ˆé€šå¸¸åº”è¯¥åœ¨0.01-10ä¹‹é—´ï¼‰
   - åŒ…å«NaNæˆ–Infå€¼
   - æœ€å°å€¼/æœ€å¤§å€¼æ˜æ˜¾ä¸åˆç†

#### âŒ **ä¸éœ€è¦é‡æ–°è®¡ç®—çš„æƒ…å†µ**

1. **æ•°æ®é›†å®Œå…¨ç›¸åŒ**
   - æ–‡ä»¶åã€å¤§å°ã€å†…å®¹éƒ½ä¸€è‡´
   - å¯ä»¥ç”¨ `md5sum` éªŒè¯

2. **ç»Ÿè®¡ä¿¡æ¯å·²å­˜åœ¨ä¸”æ­£ç¡®**
   - å·²æœ‰ `libero_single_task` æ¡ç›®
   - æ•°å€¼åˆç†

### å¦‚ä½•éªŒè¯æ•°æ®é›†æ˜¯å¦ç›¸åŒï¼Ÿ

```bash
# åœ¨æœ¬åœ°
cd /home/ubuntu/RoboticsDiffusionTransformer
find datasets/libero_single_task -name "*.hdf5" -exec md5sum {} \; | sort

# åœ¨è¿œç¨‹
cd /home/zhukefei/RoboticsDiffusionTransformer
find data/datasets/libero_single_task -name "*.hdf5" -exec md5sum {} \; | sort

# æ¯”è¾ƒä¸¤ä¸ªè¾“å‡ºï¼Œå¦‚æœå®Œå…¨ä¸€è‡´ï¼Œåˆ™æ— éœ€é‡æ–°è®¡ç®—
```

### å¦‚æœéœ€è¦é‡æ–°è®¡ç®—

```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Š
cd ~/RoboticsDiffusionTransformer
conda activate rdt

# è¿è¡Œè®¡ç®—è„šæœ¬
python compute_single_task_stat.py

# è¿™ä¼šæ›´æ–° configs/dataset_stat.json
# æ·»åŠ æˆ–æ›´æ–° libero_single_task çš„ç»Ÿè®¡ä¿¡æ¯
```

---

## è¿œç¨‹è®­ç»ƒç›¸å¯¹æœ¬åœ°çš„å…¶ä»–å…³é”®å·®å¼‚ ğŸ”

### 1. **è·¯å¾„é—®é¢˜** â­â­â­

#### âœ… å·²è§£å†³
- [x] é…ç½®æ–‡ä»¶åŠ è½½ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„
- [x] æ•°æ®é›†è·¯å¾„ï¼šè‡ªåŠ¨æ£€æµ‹
- [x] è®­ç»ƒè„šæœ¬ï¼šè·¯å¾„è‡ªåŠ¨é€‚é…

#### âš ï¸ éœ€è¦æ³¨æ„
```bash
# æ£€æŸ¥è¿™äº›è·¯å¾„æ˜¯å¦å­˜åœ¨
è¿œç¨‹æœåŠ¡å™¨è·¯å¾„æ£€æŸ¥ï¼š
â”œâ”€â”€ ~/RoboticsDiffusionTransformer/data/datasets/libero_single_task/  âœ“
â”œâ”€â”€ ~/RoboticsDiffusionTransformer/checkpoints/rdt-1b/model.safetensors  âš ï¸
â”œâ”€â”€ ~/RoboticsDiffusionTransformer/google/t5-v1_1-xxl/  âš ï¸
â””â”€â”€ ~/RoboticsDiffusionTransformer/google/siglip-so400m-patch14-384/  âš ï¸
```

**é¢„è®­ç»ƒæ¨¡å‹å’Œç¼–ç å™¨**: å¦‚æœä¸å­˜åœ¨ï¼Œä¼šå°è¯•ä»HuggingFaceä¸‹è½½ï¼ˆå¾ˆæ…¢ï¼ï¼‰

---

### 2. **GPUé…ç½®** â­â­â­

#### æœ¬åœ° vs è¿œç¨‹

| é¡¹ç›® | æœ¬åœ° | è¿œç¨‹ |
|------|------|------|
| GPUæ•°é‡ | 2å¼  | 8å¼  |
| GPUå‹å· | 4090 (48GB) | ? |
| CUDAç‰ˆæœ¬ | ? | ? |
| è„šæœ¬é…ç½® | `--num_processes 2` | `--num_processes 8` |

#### éœ€è¦æ£€æŸ¥
```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨
nvidia-smi  # ç¡®è®¤8å¼ GPUéƒ½å¯ç”¨
python -c "import torch; print(torch.cuda.device_count())"  # åº”è¾“å‡º8
```

#### è„šæœ¬å·²é…ç½®
```bash
# train_single_task_2gpu.sh
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  # 8å¼ GPU
--num_processes 8
--train_batch_size=4  # æ¯GPU 4ï¼Œæ€»batch=32
```

---

### 3. **ç½‘ç»œå’Œæ¨¡å‹ä¸‹è½½** â­â­

#### å¯èƒ½é‡åˆ°çš„é—®é¢˜

1. **HuggingFaceè®¿é—®æ…¢/å¤±è´¥**
   ```bash
   # è§£å†³æ–¹æ¡ˆ1: é¢„å…ˆä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
   # è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨é•œåƒ
   export HF_ENDPOINT=https://hf-mirror.com
   ```

2. **ç¼ºå°‘é¢„è®­ç»ƒæ¨¡å‹**
   ```bash
   # æ£€æŸ¥
   ls -lh checkpoints/rdt-1b/model.safetensors
   
   # å¦‚æœç¼ºå°‘ï¼Œéœ€è¦ä»æœ¬åœ°ä¼ è¾“æˆ–é‡æ–°ä¸‹è½½
   ```

3. **ç¼ºå°‘ç¼–ç å™¨**
   ```bash
   # æ£€æŸ¥
   ls google/t5-v1_1-xxl/
   ls google/siglip-so400m-patch14-384/
   
   # å¦‚æœç¼ºå°‘ï¼Œè®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ï¼ˆéœ€è¦æ—¶é—´å’Œç½‘ç»œï¼‰
   ```

#### å»ºè®®
```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šé¢„å…ˆæ£€æŸ¥
cd ~/RoboticsDiffusionTransformer

# 1. é¢„è®­ç»ƒæ¨¡å‹
if [ ! -f "checkpoints/rdt-1b/model.safetensors" ]; then
    echo "âŒ ç¼ºå°‘é¢„è®­ç»ƒæ¨¡å‹ï¼"
fi

# 2. æ–‡æœ¬ç¼–ç å™¨
if [ ! -d "google/t5-v1_1-xxl" ]; then
    echo "âš ï¸  å°†ä»HuggingFaceä¸‹è½½æ–‡æœ¬ç¼–ç å™¨ï¼ˆçº¦10-20åˆ†é’Ÿï¼‰"
fi

# 3. è§†è§‰ç¼–ç å™¨
if [ ! -d "google/siglip-so400m-patch14-384" ]; then
    echo "âš ï¸  å°†ä»HuggingFaceä¸‹è½½è§†è§‰ç¼–ç å™¨ï¼ˆçº¦5åˆ†é’Ÿï¼‰"
fi
```

---

### 4. **ç¯å¢ƒä¾èµ–** â­â­

#### éœ€è¦éªŒè¯çš„åŒ…

| åŒ…å | ç”¨é€” | æ£€æŸ¥å‘½ä»¤ |
|------|------|----------|
| torch | æ·±åº¦å­¦ä¹ æ¡†æ¶ | `python -c "import torch; print(torch.__version__)"` |
| accelerate | åˆ†å¸ƒå¼è®­ç»ƒ | `python -c "import accelerate; print(accelerate.__version__)"` |
| transformers | æ¨¡å‹åº“ | `python -c "import transformers; print(transformers.__version__)"` |
| h5py | HDF5è¯»å– | `python -c "import h5py; print(h5py.__version__)"` |
| safetensors | æ¨¡å‹åŠ è½½ | `python -c "import safetensors; print(safetensors.__version__)"` |

#### å¿«é€Ÿæ£€æŸ¥
```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨
conda activate rdt
python << 'EOF'
import sys
try:
    import torch
    import accelerate
    import transformers
    import h5py
    import safetensors
    print("âœ“ æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
except ImportError as e:
    print(f"âœ— ç¼ºå°‘ä¾èµ–: {e}")
    sys.exit(1)
EOF
```

---

### 5. **ç£ç›˜ç©ºé—´** â­â­

#### è®­ç»ƒéœ€è¦çš„ç©ºé—´

| é¡¹ç›® | å¤§å°ä¼°ç®— |
|------|----------|
| æ•°æ®é›† | ~100MB-1GB |
| é¢„è®­ç»ƒæ¨¡å‹ | ~2-3GB |
| ç¼–ç å™¨ (T5 + SigLIP) | ~10-15GB |
| Checkpoint (æ¯ä¸ª) | ~2-3GB |
| æ€»checkpoint (20ä¸ªlimit) | ~40-60GB |
| **æ€»è®¡** | **~50-80GB** |

#### æ£€æŸ¥å‘½ä»¤
```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨
df -h .
# ç¡®ä¿æœ‰è‡³å°‘ 100GB å¯ç”¨ç©ºé—´
```

---

### 6. **è®­ç»ƒé…ç½®å·®å¼‚** â­

#### æœ¬åœ° vs è¿œç¨‹å»ºè®®é…ç½®

| å‚æ•° | æœ¬åœ°(2-GPU) | è¿œç¨‹(8-GPU) | è¯´æ˜ |
|------|-------------|-------------|------|
| `num_processes` | 2 | 8 | GPUæ•°é‡ |
| `train_batch_size` | 4 | 4 | æ¯GPU batch |
| `æ€»batch size` | 8 | 32 | æ€»batch=num_processesÃ—train_batch_size |
| `gradient_accumulation_steps` | 1 | 1 | æ¢¯åº¦ç´¯ç§¯ |
| `æœ‰æ•ˆbatch size` | 8 | 32 | æ€»batchÃ—accumulation |
| `learning_rate` | 1e-4 | 1e-4 | å­¦ä¹ ç‡ |
| `max_train_steps` | 30000 | 30000 | æ€»æ­¥æ•° |
| `é¢„è®¡è®­ç»ƒæ—¶é—´` | ~10-12å°æ—¶ | ~3-4å°æ—¶ | ä¼°ç®— |

#### æ³¨æ„
- 8-GPUè®­ç»ƒæ—¶ï¼Œæœ‰æ•ˆbatch sizeæ˜¯æœ¬åœ°çš„4å€
- å¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ ç‡æˆ–warmupæ­¥æ•°
- å½“å‰é…ç½®ä½¿ç”¨ç›¸åŒçš„å­¦ä¹ ç‡ï¼ˆ1e-4ï¼‰ï¼Œåº”è¯¥æ²¡é—®é¢˜

---

### 7. **Weights & Biases (å¯é€‰)** â­

#### å¦‚æœä½¿ç”¨W&Bç›‘æ§

```bash
# åœ¨è¿œç¨‹æœåŠ¡å™¨ç™»å½•
wandb login

# æˆ–è®¾ç½®ç¦»çº¿æ¨¡å¼
export WANDB_MODE=offline
```

#### å¦‚æœä¸ä½¿ç”¨
```bash
# ç¦ç”¨W&B
export WANDB_DISABLED=true
```

---

### 8. **æ–‡ä»¶æƒé™** â­

#### éœ€è¦æ£€æŸ¥

```bash
# è®­ç»ƒè„šæœ¬æ‰§è¡Œæƒé™
chmod +x train_single_task_2gpu.sh

# è¾“å‡ºç›®å½•å†™æƒé™
mkdir -p checkpoints/single_task_scene10_2gpu
ls -ld checkpoints/single_task_scene10_2gpu
```

---

### 9. **è¿›ç¨‹ç®¡ç†** â­â­

#### å»ºè®®ä½¿ç”¨tmuxæˆ–screen

```bash
# å®‰è£…tmuxï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
sudo apt install tmux  # æˆ– yum install tmux

# åˆ›å»ºä¼šè¯
tmux new -s training

# è¿è¡Œè®­ç»ƒ
cd ~/RoboticsDiffusionTransformer
conda activate rdt
bash train_single_task_2gpu.sh

# åˆ†ç¦»ä¼šè¯: Ctrl+B, ç„¶åæŒ‰ D
# é‡æ–°è¿æ¥: tmux attach -t training
```

#### æˆ–ä½¿ç”¨nohup
```bash
nohup bash train_single_task_2gpu.sh > train.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f train.log

# æŸ¥çœ‹è¿›ç¨‹
ps aux | grep accelerate
```

---

### 10. **ç›‘æ§å’Œè°ƒè¯•** â­â­

#### è®­ç»ƒä¸­åº”è¯¥ç›‘æ§çš„

1. **GPUåˆ©ç”¨ç‡**
   ```bash
   watch -n 1 nvidia-smi
   # GPUåˆ©ç”¨ç‡åº”è¯¥æ¥è¿‘100%
   # æ˜¾å­˜ä½¿ç”¨åº”è¯¥ç¨³å®š
   ```

2. **è®­ç»ƒæ—¥å¿—**
   ```bash
   tail -f train.log
   # æŸ¥çœ‹losså˜åŒ–
   # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
   ```

3. **Checkpointä¿å­˜**
   ```bash
   watch -n 30 "ls -lht checkpoints/single_task_scene10_2gpu/ | head"
   # æ¯2000æ­¥åº”è¯¥ä¿å­˜ä¸€ä¸ªcheckpoint
   ```

4. **ç£ç›˜ç©ºé—´**
   ```bash
   watch -n 60 "df -h ."
   # ç¡®ä¿ä¸ä¼šæ»¡ç›˜
   ```

---

## å®Œæ•´æ£€æŸ¥æ¸…å• ğŸ“‹

### åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šè¿è¡Œï¼š

```bash
# 1. è¿æ¥åˆ°è¿œç¨‹æœåŠ¡å™¨
ssh -J zhukefei@134.175.121.223 zhukefei@172.16.0.27

# 2. è¿›å…¥é¡¹ç›®ç›®å½•
cd ~/RoboticsDiffusionTransformer

# 3. æ¿€æ´»ç¯å¢ƒ
conda activate rdt

# 4. è¿è¡Œè‡ªåŠ¨æ£€æŸ¥è„šæœ¬
bash remote_training_check.sh
```

### æ£€æŸ¥è„šæœ¬ä¼šéªŒè¯ï¼š

- âœ“ Pythonå’ŒCondaç¯å¢ƒ
- âœ“ GPUæ•°é‡å’ŒçŠ¶æ€
- âœ“ æ•°æ®é›†æ–‡ä»¶å­˜åœ¨æ€§
- âœ“ **æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ (é‡è¦!)**
- âœ“ é…ç½®æ–‡ä»¶å®Œæ•´æ€§
- âœ“ é¢„è®­ç»ƒæ¨¡å‹å­˜åœ¨æ€§
- âœ“ è¾“å‡ºç›®å½•å’Œç£ç›˜ç©ºé—´
- âœ“ è®­ç»ƒè„šæœ¬æƒé™
- âœ“ Pythonä¾èµ–åŒ…
- âœ“ ç½‘ç»œå’ŒHuggingFaceè¿æ¥

---

## ç»Ÿè®¡ä¿¡æ¯è¯¦ç»†è¯´æ˜ ğŸ“Š

### ä¸ºä»€ä¹ˆç»Ÿè®¡ä¿¡æ¯è¿™ä¹ˆé‡è¦ï¼Ÿ

```python
# åœ¨è®­ç»ƒä»£ç ä¸­ (data/hdf5_libero_dataset.py)
# ç»Ÿè®¡ä¿¡æ¯ç”¨äºè®¡ç®—lossæƒé‡

# åŠ è½½å…¨å±€ç»Ÿè®¡
with open('configs/dataset_stat.json', 'r') as f:
    global_stats = json.load(f)
    
self.action_std_global = np.array(global_stats[dataset_name]['action_std'])

# ç”¨äºè®¡ç®—state_norm (lossæƒé‡)
# state_norm = 1.0 / (state_std_global + 1e-5)
# è¿™ç¡®ä¿äº†ä¸åŒç»´åº¦çš„lossæœ‰åˆé€‚çš„æƒé‡
```

### ç»Ÿè®¡ä¿¡æ¯åŒ…å«ä»€ä¹ˆï¼Ÿ

```json
{
  "libero_single_task": {
    "action_mean": [128ä¸ªå€¼],      // åŠ¨ä½œå‡å€¼
    "action_std": [128ä¸ªå€¼],        // åŠ¨ä½œæ ‡å‡†å·® â­
    "action_min": [128ä¸ªå€¼],        // åŠ¨ä½œæœ€å°å€¼
    "action_max": [128ä¸ªå€¼],        // åŠ¨ä½œæœ€å¤§å€¼
    "state_mean": [128ä¸ªå€¼],        // çŠ¶æ€å‡å€¼
    "state_std": [128ä¸ªå€¼],         // çŠ¶æ€æ ‡å‡†å·® â­
    "state_min": [128ä¸ªå€¼],         // çŠ¶æ€æœ€å°å€¼
    "state_max": [128ä¸ªå€¼]          // çŠ¶æ€æœ€å¤§å€¼
  }
}
```

### å¦‚æœç»Ÿè®¡ä¿¡æ¯é”™è¯¯ä¼šæ€æ ·ï¼Ÿ

âŒ **ä½¿ç”¨é”™è¯¯çš„ç»Ÿè®¡ä¿¡æ¯ (å¦‚libero_90)**:
- lossæƒé‡ä¸æ­£ç¡®
- æŸäº›ç»´åº¦è¢«è¿‡åº¦æƒ©ç½šæˆ–å¿½ç•¥
- è®­ç»ƒä¸ç¨³å®šæˆ–æ”¶æ•›åˆ°é”™è¯¯çš„è§£
- **è¿™å°±æ˜¯ä¹‹å‰è®­ç»ƒæ•ˆæœä¸å¥½çš„åŸå› ä¹‹ä¸€ï¼**

âœ… **ä½¿ç”¨æ­£ç¡®çš„ç»Ÿè®¡ä¿¡æ¯ (libero_single_task)**:
- lossæƒé‡åˆç†
- æ‰€æœ‰ç»´åº¦å¹³è¡¡å­¦ä¹ 
- è®­ç»ƒç¨³å®šæ”¶æ•›

---

## å¿«é€Ÿå†³ç­–æµç¨‹ ğŸ¯

```
å¼€å§‹
  â†“
è¿œç¨‹æ•°æ®é›† == æœ¬åœ°æ•°æ®é›†ï¼Ÿ
  â†“                    â†“
 æ˜¯                   å¦
  â†“                    â†“
ç»Ÿè®¡ä¿¡æ¯å·²å­˜åœ¨ï¼Ÿ      é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯ï¼
  â†“          â†“          â†“
 æ˜¯         å¦          â†“
  â†“          â†“          â†“
ç›´æ¥è®­ç»ƒ   è®¡ç®—ç»Ÿè®¡   ä½¿ç”¨æ–°ç»Ÿè®¡è®­ç»ƒ
```

---

## æ¨èæµç¨‹ â­

### ç¬¬ä¸€æ¬¡åœ¨è¿œç¨‹æœåŠ¡å™¨è®­ç»ƒ

```bash
# 1. è¿æ¥åˆ°æœåŠ¡å™¨
ssh -J zhukefei@134.175.121.223 zhukefei@172.16.0.27

# 2. è¿›å…¥é¡¹ç›®
cd ~/RoboticsDiffusionTransformer
conda activate rdt

# 3. è¿è¡Œå®Œæ•´æ£€æŸ¥
bash remote_training_check.sh

# 4. æ ¹æ®æ£€æŸ¥ç»“æœå†³å®šæ˜¯å¦é‡æ–°è®¡ç®—ç»Ÿè®¡
# å¦‚æœéœ€è¦:
python compute_single_task_stat.py

# 5. å¼€å§‹è®­ç»ƒ
tmux new -s training
bash train_single_task_2gpu.sh

# 6. åˆ†ç¦»ä¼šè¯ (Ctrl+B, D)

# 7. ç›‘æ§
tmux attach -t training  # æŸ¥çœ‹è®­ç»ƒ
nvidia-smi  # æŸ¥çœ‹GPU
```

---

## æ€»ç»“ ğŸ“

### æœ€å…³é”®çš„3ç‚¹

1. **æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯** - å¦‚æœè¿œç¨‹æ•°æ®é›†ä¸åŒï¼Œå¿…é¡»é‡æ–°è®¡ç®—
2. **é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„** - ç¡®ä¿ checkpoints/rdt-1b/model.safetensors å­˜åœ¨
3. **GPUé…ç½®** - è„šæœ¬å·²é…ç½®ä¸º8-GPUï¼Œç¡®è®¤æœåŠ¡å™¨æœ‰8å¼ å¯ç”¨GPU

### å·²ç»è‡ªåŠ¨å¤„ç†çš„

âœ… ä»£ç è·¯å¾„é—®é¢˜ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
âœ… æ•°æ®é›†è·¯å¾„è‡ªåŠ¨æ£€æµ‹
âœ… è®­ç»ƒè„šæœ¬å·²é…ç½®ä¸º8-GPU
âœ… é…ç½®æ–‡ä»¶åŠ è½½ä½¿ç”¨ç›¸å¯¹è·¯å¾„

### éœ€è¦æ‰‹åŠ¨æ£€æŸ¥çš„

âš ï¸ æ•°æ®é›†æ˜¯å¦ä¸æœ¬åœ°ä¸€è‡´
âš ï¸ ç»Ÿè®¡ä¿¡æ¯æ˜¯å¦æ­£ç¡®
âš ï¸ é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨
âš ï¸ GPUæ˜¯å¦éƒ½å¯ç”¨
âš ï¸ ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³

---

**å»ºè®®**: å…ˆè¿è¡Œ `bash remote_training_check.sh`ï¼Œæ ¹æ®è¾“å‡ºå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼

